{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6705,"status":"ok","timestamp":1718960162282,"user":{"displayName":"white blue","userId":"17600182665673203811"},"user_tz":-540},"id":"ZtPQhdL9Onmf"},"outputs":[],"source":["import os\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","import torch.nn.functional as F\n","\n","\n","base_dir = os.getcwd() + \"/\"\n","\n","# base_dir = \"/content/drive/MyDrive/bookend/dev/text-style-classify/basic/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18762,"status":"ok","timestamp":1718960204985,"user":{"displayName":"white blue","userId":"17600182665673203811"},"user_tz":-540},"id":"Mn10aYi4AtN2","outputId":"4946320a-1e19-418f-e053-95008101ba57"},"outputs":[],"source":["\"\"\"from google.colab import drive\n","drive.mount('/content/drive')\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":197962,"status":"ok","timestamp":1718960406769,"user":{"displayName":"white blue","userId":"17600182665673203811"},"user_tz":-540},"id":"09azWz_vQALE"},"outputs":[],"source":["df = pd.read_pickle(base_dir + 'data/labeled_compact.pkl')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max([len(l) for l in df['tokenized_sentence'].to_list()])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, max_length=64):\n","        df = df.reset_index(drop=True)\n","        self.sentences = df['tokenized_sentence'].tolist()\n","        self.labels = df['encoded_author'].tolist()\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","    \n","    def __getitem__(self, idx):\n","        sentence = self.sentences[idx]\n","        label = self.labels[idx]\n","        \n","        # 텐서 복사\n","        input_ids = sentence.clone().detach()\n","        attention_mask = torch.tensor([input_ids[i] != 0 for i in range(len(input_ids))])\n","\n","        return {\n","            'input_ids': input_ids.flatten(),\n","            'label': torch.tensor(label, dtype=torch.long),\n","            'attention_mask': attention_mask.flatten()\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_dataset = CustomDataset(train_df)\n","val_dataset = CustomDataset(val_df)\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model_name, num_classes=3763, hidden_size=256):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name)\n","        self.fc1 = nn.Linear(self.bert.config.hidden_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, input_ids, attention_mask=None):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_output = outputs.pooler_output\n","        x = self.fc1(cls_output)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = BERTClassifier('distilbert-base-multilingual-cased', num_classes=3763, hidden_size=128)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","criterion = nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = 3\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    \n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","        \n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","        \n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        loss = criterion(outputs, labels)\n","        \n","        total_loss += loss.item()\n","        \n","        loss.backward()\n","        optimizer.step()\n","    \n","    avg_train_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch + 1}, Loss: {avg_train_loss}')\n","    \n","    # Validation\n","    model.eval()\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    \n","    for batch_idx, batch in enumerate(val_loader):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","        \n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","        \n","        loss = criterion(outputs, labels)\n","        \n","        total_eval_loss += loss.item()\n","        \n","        preds = torch.argmax(outputs, dim=1).flatten()\n","        accuracy = (preds == labels).cpu().numpy().mean() * 100\n","        total_eval_accuracy += accuracy\n","        print(f\"Validation Batch: {batch_idx + 1}, Loss: {loss.item()}, Accuracy: {accuracy}\")\n","    \n","    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n","    avg_val_loss = total_eval_loss / len(val_loader)\n","    \n","    print(f'Validation Accuracy: {avg_val_accuracy}')\n","    print(f'Validation Loss: {avg_val_loss}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.1.-1"}},"nbformat":4,"nbformat_minor":0}
